\chapter{Outlook} \label{ch:outlook}

The research presented in this thesis explore ways in which data-driven approaches based on machine learning can be leveraged in the design-make-test cycle of drug discovery. In each of the three steps of `design', `make', and `test' we encounter the same underlying challenge, of grappling with the practical difficulties of a drug discovery campaign where we must make full use of the limited data available.

In Chapter \ref{ch:fresco} we looked at how to leverage fragment-protein structures from a crystallographic fragment screen to hit discovery in the absence of any bioactivity data. Using an unsupervised learning approach, we learn the geometric distribution of pharmacophores from the fragment-protein complexes, and use these to screen potential molecules for bioactivity. We showed that this approach outperforms docking on distinguishing active compounds from inactive ones on retrospective data. Further, we prospectively found novel hits for SARS-CoV-2 Mpro and the Mac1 domain of SARS-CoV-2 non-structural protein 3 by virtually screening a library of 1B molecules.

Chapter \ref{ch:ranking} takes us to the early stages of hit-to-lead molecular optimisation where bioactivity data is limited, noisy, and dominated by inactive molecules. We overcame this challenge with a learning-to-rank framework via an ML model that predicts whether a compound is more or less active than another. This approach allowed us to make use of inactive data and threshold the bioactivity differences above measurement noise, and validation on retrospective data for SARS-CoV-2 Mpro showed that we can outperform docking on ranking ligands. Combining this model with AI-based synthesis tools, we prospectively screened a library of 8.8M molecules to arrive at a potent compound with a novel scaffold.

While AI-based synthesis tools have already shown demonstrable success in accelerating the synthesis of new molecules, they are still prone to failure and suffer from a lack of transparency in their decision making due to their black-box nature. To address this, in Chapter \ref{ch:transformer} we showcased a workflow for quantitatively interpreting a state-of-the-art deep learning model for reaction prediction. By analysing chemically selective reactions, we showed examples of correct reasoning by the model, explain counterintuitive predictions, and identify Clever Hans predictions where the correct answer is reached for the wrong reason due to dataset bias.

In Chapter \ref{ch:testing} we explored how to accelerate testing procedures by applying machine learning on bioactivity data from nanomolar-scale high-thoughput chemistry. While this experimental technique greatly increases the number of molecules that can be tested, there is additional noise resulting from having to assay crude reaction mixtures instead of pure samples. Nevertheless, we showed that machine learning models trained on this data is able to cut through this noise and identify a false negative assay measurement, as well as prospectively screen a library of ~62K molecules to discover new SARS-CoV-2 Mpro inhibitors just as potent as those from the original assay.

\section{Directions for Future Research}

While we have explored some methods to accelerate the design-make-test cycle in this thesis, there is still much more work to be done to bring us closer to the dream of efficient and automated drug discovery. Below, we outline some of the most prominent directions for future research.

\subsection{Synthesis}
Machine learning (ML)-based models for synthesis prediction have made significant strides in recent years, providing valuable insights and guidance in the design of synthesis routes in industry. These models leverage advanced algorithms to analyze vast amounts of chemical data, allowing researchers to make predictions about the outcomes of chemical reactions, optimize reaction conditions, and identify potential pitfalls that could impede successful synthesis. The success of these models has prompted many chemical companies to integrate them into their workflows, enabling more efficient and cost-effective drug discovery and materials development.

However, there is still a need for more powerful software tools that can streamline the logistics and user experience of chemical route design, particularly for non-specialist users. While ML-based models are incredibly valuable, they can be complex and difficult to use, especially for those without a background in chemistry. To address this challenge, there are exciting opportunities to develop software tools that can connect these models with commercial compound databases, making it easier for researchers to search for and identify potential chemical starting materials, intermediates, and reagents. By simplifying the process of chemical route design, these tools could help accelerate research and development efforts in the chemical industry.

Recent pioneering work has demonstrated the potential of large language models to connect user queries in natural language with PubChem database searching and ordering from commercial vendors. These models can effectively interpret complex user requests and search for relevant compounds within the database, providing users with an intuitive and user-friendly interface for chemical route design. The success of these models highlights the potential for further development in this area, and the need to continue refining these tools to improve their accuracy and usability.

In order to advance the field of synthesis prediction, it is crucial to continue seeking improvements in model architectures, assimilating data from industry, and designing better benchmarks for evaluating model performance. As the field of ML-based synthesis prediction continues to evolve, it is becoming increasingly clear that more sophisticated model architectures are necessary to accurately capture the complexity of chemical reactions. Additionally, the incorporation of standardised data (mention ELNs) from industry can help researchers develop more robust models that are better suited for real-world applications. Finally, the creation of better benchmarks can help ensure that models are evaluated under realistic conditions, providing a more accurate representation of their capabilities.

Finally, there is a need to shift the focus of synthesis prediction models towards predicting reaction yields, and transferring that expertise towards chemical engineering applications where chemical reactions must be scaled up to kilogram-scale compound synthesis. While existing models are effective at predicting the outcomes of small-scale chemical reactions, they may not be as accurate when it comes to predicting the behavior of reactions that must be scaled up for large-scale production. By focusing on predicting reaction yields, researchers can develop more robust models that are better suited for industrial applications, helping to bridge the gap between research and production.

\subsection{Making better use of existing data}

A common challenge in drug discovery is the limited availability of data. While it is true that data scarcity is a persistent issue, it is also true that we are not making the most of the data that we do have. Existing datasets can be enhanced by utilizing them in more effective ways, and by designing models specifically for low-data regimes. By adapting our approach, we can improve the accuracy of models and gain valuable insights into chemical space.

To overcome the challenge of data scarcity, we can adapt and design models specifically for low-data regimes. For example, imputation-based methods or further transfer learning can help us make more accurate predictions even with limited data. Imputation-based methods involve filling in missing data points with estimates derived from other data points, allowing researchers to make use of incomplete datasets. Transfer learning, on the other hand, involves using knowledge gained from one domain to inform the learning process in another domain. By developing and utilizing models that are specifically designed for low-data regimes, we can make more accurate predictions and gain insights that would not be possible with traditional models.

Federated learning is another promising approach that can help overcome data scarcity while maintaining data privacy. This method involves training models on data from multiple industry partners, allowing us to leverage a much larger dataset without compromising the privacy of the underlying data. One recent case study is the Molecular Entity Learning from Optimized Destruction and Deletions of Yeasts (MELODDY) project, which has brought together leading pharmaceutical companies to create a federated learning platform for drug discovery. By sharing data in a secure and private manner, we can make more accurate predictions and gain valuable insights into chemical space.

Finally, we can also leverage noisy but high-throughput experimental techniques to generate more data for drug discovery. One example of such a technique is DNA-encoded libraries, which enable the synthesis and screening of large numbers of compounds in a relatively short amount of time. While the resulting data may be noisy, the sheer volume of data generated makes it a valuable resource for model training and validation. By integrating data from these and other high-throughput techniques with traditional data sources, we can enhance our understanding of chemical space and improve the accuracy of drug discovery models.

\subsection{Integrate protein information into property prediction}
Accurate bioactivity prediction is still the primary bottleneck for computational drug design. Despite significant progress in recent years, predicting the efficacy of a drug candidate remains a complex challenge that involves a wide range of factors.

Recent advances in machine learning for protein bioinformatics offer promising new approaches to address this challenge. For example, researchers have developed deep learning models to predict protein structure and function, which can inform drug design strategies. By integrating these models and workflows with those for ML in chemistry and cheminformatics, we may be able to make significant breakthroughs in bioactivity prediction.

Expanding beyond bioactivity prediction, these models and workflows also have potential for predicting ADME/Tox properties, which can be even more challenging than bioactivity prediction. By improving our ability to predict how a drug candidate will interact with biological systems, we can design more effective and safer drugs.

Finally, these advances may also have applications in predicting the molecular mechanisms of action, as well as identifying new drug targets. By combining insights from both chemical and biological data, we can gain a more comprehensive understanding of how drugs interact with the body at a molecular level, opening up new opportunities for drug discovery and design.

\subsection{Fully automated drug discovery}
Full automation of the drug discovery process is an ambitious goal that many researchers are working towards. The aim is to develop systems that can perform multiple iterations of the design-make-test process autonomously, with all decision-making handled by the system.

Recent developments in antibody design demonstrate the potential of this approach. Researchers have used machine learning to design and test thousands of potential antibody candidates, identifying promising new drug targets with unprecedented speed and accuracy.

However, achieving full automation of drug discovery will require integrating all of the models and workflows mentioned above, and developing new approaches to optimize decision-making and resource allocation. Reinforcement learning, in particular, could be the ultimate embodiment of this vision, enabling systems to learn from experience and continually improve their performance.

That said, the computational resources required for such an approach may be prohibitive in the near term, and significant technological breakthroughs will be required to make full automation of drug discovery a practical reality. Nonetheless, the potential benefits of such an approach are enormous, with the potential to transform the field of drug discovery and accelerate the pace of new drug development.
