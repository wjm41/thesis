\chapter{Background} \label{ch:background}

Detailed description of many things

\begin{itemize}
    \item SMILES
    \item scaffolds
    \item fingerprints
    \item pharmacophores
    \item measuring affinities
    \item docking
    \item machine learning
    \begin{itemize}
        \item random forest
        \item gaussian process?
        \item deep learning
        \item transformer
        \item train-test-splitting
    \end{itemize}
    
\end{itemize}

\section{Molecular Transformer}
% The task in organic chemical reaction prediction is to predict the outcome (product or products) and potentially the yield of some organic reaction given the reactants, reagents, catalysts and conditions such as the solvent, temperature, reaction time etc.  This is both an academic and an industrial problem. It is of scientific interest to understand the different factors determining the outcome of reactions that are essential for the design of a successful reaction prediction model but it is also of interest for industry, in particular the pharmaceutical industry who wants to be able to synthesise drug candidate molecules quickly and efficiently to accelerate the drug discovery pipeline. There are several ways of tackling this problem all of them can be useful for different aspects of the prediction problem. \par

% \section{\emph{Ab-initio} reaction prediction}

% When trying to optimize certain reactions to find for example the best catalyst, a full modelling approach based on quantum mechanics is often used \cite{Shan2017PracticalApplications}. These methods can be very accurate, but their use is limited to expert theoreticians and relatively simple systems. If one wants to simulate reactions of larger systems an alternative can be the use of reactive force fields like ReaxFF \cite{Senftle2016TheDirections}. This approach relies on classical interatomic potentials which have the benefit of cheap evaluation but also allows bond breaking and forming unlike classical force fields which usually require pre-defined connectivity of the atoms. Another method often used to predict the selectivity of some particular type of reaction with high accuracy relies on properties of the reactants and reagents obtained using quantum chemical calculations. For example to determine the most probable reaction site in electrophilic aromatic substitution reaction the RegioSQM method finds the aromatic carbon with the lowest free energy of protonation. It is shown by the authors that this carbon is the most reactive site in over 96\% of the reactions considered in the paper \cite{Xu2014MechanismAlcohols}. Another notable example is the method developed by Cao et. al. which automates quantum chemical calculations at the density functional theory level and makes predictions based on them without requiring any expertise in computational methods \cite{Cao2020InReactions}.  They concentrate on Pd catalysed C - H activation reactions and determine the most probable outcome by automatically generating possible intermediate structures and using their energies as a proxy for the energy barrier of the reaction to proceed via the given route. \par

% \section{Rule-based reaction prediction}

% Often it is not necessary to fully simulate and understand a chemical reaction and it is sufficient to know the outcome i.e. the major product of it. This is most often the case when experimental organic chemists are willing to validate their synthetic route or when a synthesis planning software uses a reaction prediction model to score its suggestions. This is what is more traditionally referred to as reaction prediction. In these use cases a general purpose model that is able to predict a wide variety of organic reactions with good accuracy is desired. Trained organic chemists usually rationalize reactions based on the reaction mechanisms \cite{Clayden2012}. These mechanisms can be used to categorize organic reactions and each of these categories can be summarised with the help of so called reaction templates. Figure~\ref{fig:rx_template} shows a typical general reaction template for the synthesis of an amide using acid chloride and an amine. Here the $R_1$ and $R_2$ represent any chemical structures. 
% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.75\textwidth]{Chapter2/Figs/Raster/rx_template.png}
% \caption[Reaction template]{An example of a reaction template for the synthesis of an amide}
% \label{fig:rx_template}
% \end{figure}
% These templates can be used for organic reaction prediction by building a catalogue of templates of as many organic reactions as possible. Then given some reactants and reagents as labelled graphs the problem of reaction prediction is transformed into one of subgraph searching to find the best matching general template in the catalogue. When that template is found it can be applied on the input to obtain the predicted outcome of the reaction. This approach was originally proposed and pioneered in the 1980s by E. J. Corey when he used templates for the reverse problem of retrosynthesis \cite{Corey1985Computer-assistedSynthesis}. The template-based approach had some success in forward reaction prediction for example as described in Ref~\cite{Klucznik2018EfficientLaboratory} a template-based model helped design synthetic pathways to a diverse set of 8 drug-like molecules. This method had considerably more success  in retrosynthesis though where there does not exist a single correct solution. One of the major limitation of template-based approaches when applied to forward prediction is scalability, meaning that the template library needs to be maintained and every time a new reaction is reported the associated template needs to be added to the template library. A further problem is that it is often not obvious which parts of the molecule are crucial for a given reaction. This means that given a reaction one can derive a smaller more general template or a larger one that is more specific for the particular reaction. This results in either too many templates matching a particular input resulting in many equally possible reaction outcomes or in the case of larger more specific templates the library will grow very big which results in very slow predictions.  \par

% \section{Data-driven reaction prediction}

% Modern approaches to reaction prediction increasingly rely on experimentally reported chemical reaction data instead of the knowledge of mechanisms. This can be advantageous for a number of reasons. The revolution of machine learning, pattern recognition and artificial intelligence resulted in a number of powerful methods developed in different fields such as natural language processing or graph generation that can be adapted for reaction prediction. These algorithms together with the several datasets containing hundreds of thousands or millions of reactions extracted from publications and patents using text mining have the potential for the development of successful models. These data driven models have the advantage that they can in principle build on all published reactions in the literature that no human chemist could look through to code up by hand. Furthermore, by learning from vast amount of data these machine learning models have the potential of learning complex chemical relationships resulting in better generalization. This is essential as the expectation for the reaction prediction models is to perform well on unseen molecules and potentially unseen reactions making them more than a simple searchable database. A limitation of these approaches is that the reaction databases often only contain the reactants and reagents and the major products, but not the minor products, yields, temperatures or other conditions. This makes the reaction prediction task an ill-posed problem. It is often the case that conditions such as temperature play a key role in determining the reaction outcome. For example in the case of enolate chemistry low temperature favours the formation of the kinetic, high temperature the thermodynamic enolate resulting in different selectivity \cite{Clayden2012}. Without specifying the temperature in these cases the major product cannot be determined. \par

% The first approach to data driven reaction prediction is very similar to the simple template based reaction prediction discussed above the only difference being that the templates are automatically extracted from the databases rather than being hand crafted \cite{Bgevig2015RoutePrediction, Kayala2012ReactionPredictor:Learning, Kayala2011LearningReactions,  Socorro2005ROBIA:Program}. This solves the issue of scalability but suffers from much of the same problems with the small templates being too general and large templates being too specific.  \par

% Machine learning models can also be used to directly predict the outcome of chemical reactions. These template-free approaches do not require any subgraph searching which results in much faster predictions. Another advantage is that since they are not directly memorizing templates from the training datasets they have the potential of better generalization by inferring some of the underlying reactivity trends. One of the first successful machine learning based model was proposed by Coley et. al. in 2017 \cite{Coley2017PredictionLearning}. Their approach builds on the template based models and combines them with neural networks. First a number of candidate products are generated using general templates extracted form the literature. These candidate templates are than scored using a neural network model trained to identify the major product. \par
% An improved model published by the same group has abandoned templates entirely \cite{ Coley2019AReactivity, Jin2017}. They have made use of the observation that usually only a small number of atoms and bonds participate directly in a chemical transformation. By considering the reactants and reagents as molecular graphs and the reaction as a series of graph edits they trained a reaction centre identifier network. This network selects a small number of atom pairs that are most likely to be involved in the reaction. All possible chemically valid graph edits are than considered on these centres. It is important to note that not all bond changes on the reaction centres have identical probabilities, and a product that results from more probable bond changes is itself more probable. This provides an initial ranking of the possible products. This generated ranking of products is then refined by a Weisfeiler-Lehman Difference Network, a type of graph convolutional neural network, to find the most probable product structure.  Together with the model they have also published a dataset of ca 480 000 reactions filtered from the text mining work of Lowe \cite{Lowe2012}. They have achieved 85\% accuracy on this dataset outperforming the previous state-of-the-art by more than 10\%. The key strength of this approach is that interpretability is built into the design of the algorithm. The way the model is predicting the sequence of graph edits is very similar to how humans would write arrow-pushing mechanisms of organic reactions\cite{Clayden2012}. This way one can get a direct insight into how the model is arriving at certain predictions. This is in contrast to previous reaction prediction approaches that were trying to directly learn mechanisms based on expert crafted rules as a supervised learning problem \cite{Bradshaw2019APaths, Kayala2012ReactionPredictor:Learning}.  \par

% In the 2010s natural language processing (NLP) and neural machine translation saw a huge revolution \cite{Young2018RecentProcessing}. This led scientists from different fields to the realization that many problems can be cast in a sequence-to-sequence formalism. This allowed them to use the powerful tools of NLP in a variety of applications. The first attempt to formulate the reaction prediction problem in a sequence-to-sequence manner came by Nam and Kim \cite{Nam2016LinkingReactions}. They have used a text based representation of organic molecules called SMILES \cite{Weininger1988, Weininger1989}. SMILES strings represent atoms with their chemical symbols and aromatic atoms with lowercase letters. Single and aromatic bonds are omitted while for double and triple bonds the specials characters \texttt{=} and \texttt{\#} are used. Branches are specified by enclosing them into parentheses. To encode cyclic structures a single bond in the ring is broken and the matching atoms are denoted by numbers. These rules lead to a large number of valid SMILES representations for larger molecules. To make the mapping injective a deterministic algorithm is used to enumerate the nodes of the molecular graph. Following this ordering a unique canonical text representation of organic molecules is obtained. This representation forms the basis for all of the text-based models discussed later. 
% A few examples of the SMILES syntax with the corresponding structures is shown below. 

% \begin{table}[h!]
% \begin{center}
%     \begin{tabular}{|c|c|}
%     \hline
%          SMILES & Structure \\
%          \hline
%          C & CH\textsubscript{4} \\
%          \lbrack Fe2+\rbrack & Fe\textsuperscript{2+} \\
%          C=O & CH\textsubscript{2}O \\
%          C\#N & HCN (cyan) \\
%          CCN(CC)CC & \includegraphics[width=0.75in]{triethyl_amine.png} \\
%          CC1=CC(CCC1)Br & \includegraphics[width=0.7in]{cyclic.png} \\
%          \hline
%     \end{tabular}
%     \caption{Demonstration of the SMILES language}
%     \label{table:smiles}
% \end{center}
% \end{table}

% In the paper of Nam and Kim they formulated the reaction prediction problem as a translation task. The input SMILES corresponding to the reactant and reagent molecules are tokenized, so that each character of SMILES is equivalent to a word and the whole input is equivalent to a sentence. This sentence is than ``translated" by the model to the product SMILES. Neural machine translation models are trained using a large parallel corpus. This is available in the case of organic reactions from patents and publications or can be generated using templates of elementary reactions. The method of Nam and Kim served as an important proof of concept but could not match the accuracy of rule-based and graph-to-graph models. \par
% %The method was built on a neural network building block called gated recurrent unit (GRU) \cite{Cho2014LearningTranslation}. GRUs are a type of recurrent neural networks that process arbitrarily long inputs token by token, so that the hidden state representation of each token depends on the previous ones. %The model used in the paper is illustrated on Figure~\ref{fig:gru}. 
% %This model served as a proof-of-concept but could not match the accuracy of graph-to-graph and template based approaches. \par

% \iffalse
% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.9\textwidth]{Chapter2/Figs/Raster/gru.png}
% \caption[GRU for reaction predictions]{The architecture used by Nam and Kim. The input SMILES string is tokenized into ``words", each token is embedded using a learnt embedding and processed by a three layer GRU network. The product is generated using attention mechanism.}
% \label{fig:gru}
% \end{figure}
% \fi

% The large breakthrough of sequence-to-sequence models for reaction prediction came after the introduction of a new and innovative architecture for neural machine translation by Vaswani et. al. \cite{Vaswani2017}. The so called Transformer model revolutionized the entire industry of machine translation and found use in many other areas of machine learning ever since. In the next section the Transformer architecture is described in detail followed by a discussion of the Molecular Transformer. 

% \section{The Molecular Transformer}

% \subsection{The Transformer architecture}

% The Transformer architecture was originally developed for machine translation tasks. It has an encoder-decoder structure. Both the encoder and the decoder are made up of so called transformer blocks that process the inputs by applying a multi-head scaled dot-product attention mechanism followed by layer normalization and some fully connected feed forward layers. In the following each part is described in detail. 

% \subsubsection{Encoder}
% The input to the model is a sentence made up of different words that are contained in a vocabulary. Each word in the vocabulary has a learnt fixed-length vector representation. Passing these vectors to the model would not be enough though as these vectors have no reference to where the given word appears inside the sequence. To encode this information as well another vector of the same length is added to each word-vector that depends on the position inside the sequence: \par

% \begin{equation}
%     PE_{(pos, 2i)}=\sin(pos/10000^{2i/d_{model}})
% \end{equation}
% \begin{equation}
%     PE_{(pos, 2i+1)}=\cos(pos/10000^{2i/d_{model}})
% \end{equation}

% This vector representation of the input text is passed into the transformer blocks. These consist of a multi-head attention layer with residual connection \cite{He2016DeepRecognition} followed by layer normalization \cite{Ba2016LayerNormalization} and a 2-layer fully connected feed forward neural network with ReLU activation. The encoder of the model is made up of $N=6$ transformer blocks as illustrated on Figure~\ref{fig:transformer}

% \begin{figure}[ht]
% \centering    
% \includegraphics[width=2.9in]{transformer_diagram.png}
% \caption{Graphical illustration of the full transformer model \cite{Vaswani2017}}
% \label{fig:transformer}
% \end{figure}

% \subsubsection{Multi-head scaled dot-product attention}
% The multi-head scaled dot-product attention is the heart of the Transformer model. It is a specific version of a general deep learning technique called attention. Given a set of vector \emph{values} and a vector \emph{query} the attention mechanism computes a weighted sum of the \emph{values} dependent on the \emph{query}. The sum represents a selective summary of the \emph{values} and the \emph{query} determines the importance of each vector, i. e. determines how much each \emph{value} vector is attended to.\par 
% The full attention mechanism operates by performing the following steps. Given some vector values $\bm{h_1}, \bm{h_2},\dots, \bm{h_N} \in \mathbb{R} ^{d_1}$ and a query $\bm{q} \in \mathbb{R} ^{d_2}$ \par

% \begin{enumerate}
%     \item First the attention scores $\bm{e} \in \mathbb{R}^N$ are computed. In the case of the scaled dot-product attention $d_1=d_2$ and $\bm{e}$ is simply defined as the scaled vector of projections $e_i=\frac{\bm{q}^\intercal \bm{h}_i}{\sqrt{d_1}}$
%     \item To generate the attention distribution $\bm{\alpha}$ the softmax of $\bm{e}$ is taken: 
%     \begin{equation}
%         \alpha_i=\frac{\exp{(e_i)}}{\sum_{j=1}^N \exp{(e_j)}} 
%         \label{eqn:softmax}
%     \end{equation}
%     \item Finally the attention distribution is used to take the weighted sum of the values to obtain the final output
%     \begin{equation}
%         \bm{a}=\sum_{i=1}^N \alpha_i \: \bm{h}_i \; \in \mathbb{R}^{d_1}
%     \end{equation}
% \end{enumerate}

% The scaling factor in the dot product serves the purpose of preventing some of the projection becoming overwhelmingly large which in turn would lead to the softmax function being sharply peaked around those values and being shallow everywhere else. This would result in very small gradients at most places that can substantially slow down the training.\par

% In the Transformer encoder the above described attention mechanism is used such that given a set of input vectors a new vector is calculated for all of them (being the query) from the others (being the keys). This is called self-attention. This way during training the model is able to learn which vectors (that are representing words or atoms) usually interact with each other. This interaction can result in a large value in the attention distribution. \par

% Usually the input, be it a chemical formula or a sentence contains a rich structure with the words affecting each others meanings in multiple ways. The problem with the simple self-attention mechanism is that by defining a single attention distribution for each input vector only one way of interaction can be learnt by the model. To give the model more flexibility to potentially learn more complex interaction structures multi-head attention was introduced. This mechanism maps the vectors to $h=8$ different lower dimensional spaces via a set of learnt linear transformations. The self-attention mechanism is than applied in these lower dimensional spaces simultaneously. The outputs of the different attention heads are finally concatenated and fed into a linear neural network layer. The whole mechanism is illustrated on Figure~\ref{fig:multihead_attention}

% \begin{figure}
% \centering    
% \includegraphics[width=2.2in]{mulithead_attention.png}
% \caption{Graphical illustration of the multi-head attention \cite{Vaswani2017}}
% \label{fig:multihead_attention}
% \end{figure}

% \subsubsection{Decoder}

% The outputs of the encoder which are $N$ vectors if the input sequence is $N$ words long are fed into the decoder which has a structure almost identical to the encoder. The first modifications concern the masking in the multi-head self-attention layers to make sure that every token in the output translation can only attend to the preceding ones. The second modification of the attention mechanism is making use of the encoder outputs by using them as keys whilst the queries are the outputs of the previous decoder layer. \par
% The generation of the translation happens in a sequential manner. First the embedding of the special \texttt{<start>} token is fed into the decoder and passed through the layers. The result is projected to a vector that has the same dimensionality as the size of the vocabulary. Finally the softmax function is applied to obtain the probability of the first word. The second word is generated by passing in the first word (and the \texttt{start} token) to the decoder, the third is generated by passing in the first and the second etc. This is called autoregressive translation. Finally the translation terminates either when the most probable next token is the special \texttt{<end>} token or when the maximum sequence length is reached. By multiplying together the next-token probabilities and normalizing with respect to the length of the output a confidence score of the translation can be obtained. 

% \subsection{Architecture of the Molecular Transformer}
% The Molecular Transformer architecture used throughout this work is based on the model described in Schwaller et. al. \cite{Schwaller2019MolecularPrediction}. The Transformer implementation used for this work is part of the OpenNMT natural language processing package \cite{Klein2017} which makes use of the PyTorch 1.2 framework \cite{Paszke2019PyTorch:Library}.\par
% Our implementation of the model uses a 256 dimensional learnt embedding for each SMILES token. The encoder and the decoder are both made up of 4 standard transformer layers and dropout is applied with probability 0.1 \cite{Srivastava2014Dropout:Overfittin}. For the optimization the Adam optimizer is used and the model is trained for 500 000 or 1 000 000 steps for the USPTO and Pistachio datasets respectively. Checkpoints are saved every 10 000 steps and the final model is obtained by averaging the weights of the last 20 checkpoints for USPTO and the last 10 checkpoints for Pistachio. \par
% \subsubsection{Datasets}
% The first dataset used in this work is the freely available USPTO dataset \cite{Lowe2012} that was filtered by Jin et. al. \cite{Jin2017}. Further filtering was preformed to remove some remaining duplicates or reactions that were erroneously text mined. These included examples such as reactions whose sole product is nitric acid, sulfuric acid, chloride ion etc. This way the final number of reactions in the dataset was 471 791 of which 377 419  were used for training, 23 589 for validation and 70 765 were used as a hold-out test set. The training set was augmented by an equal number of random equivalent SMILES strings. Augmentation can help the model to learn the underlying molecular graph from the SMILES sequence. \par
% The model trained in the way described above achieved 88.8\% Top-1 accuracy on the test set. This model was used throughout the interpretability experiments and is referred to as USPTO Transformer. \par
% The second dataset used was the commercial Pistachio dataset \cite{Mayfield2018Pistachio2.0}. This dataset contains over 9 million reactions text mined from US and EPO patents. This dataset was filtered similarly to USPTO to remove erroneous and duplicate reactions. It turned out that many of the 9 million reactions were duplicates corresponding to different patent IDs. In the end a dataset of 2 375 385 reactions was obtained of which 2 019 078 was used for training, 118 770 for validation and 237 537 for testing. \par
% The model trained as described above achieved 76.4\% Top-1 accuracy on the test set. Even though this looks like a substantially lower performance in reality the two models perform similarly well on new reactions. The possible reasons for the large difference in the measured performance on the held-out test sets are described in detail in Chapter~\ref{chap:interpr_molt}. This model obtained was also used in the interpretability experiments to test the effect of increased training set size on the models understanding of chemistry and is referred to as Pistachio Transformer in the rest of the thesis. \par

% \subsection{Interpretability}
% Modern machine learning and especially deep learning algorithms are often regarded as black box machines. It is thought that the more complex a learning algorithm is the better it can fit complex pattern in the data, but it comes at the expense of human interpretability. This is a criticism that is present especially in scientific applications where the goal is not only to have a predictive model, but also to gain insight into how different effects are impacting the observations. \par 

% The first step towards understanding machine learning models is to look at the ingredients of the models which are the architecture, the dataset and the learning algorithm. It has been shown that the loss landscape of deep neural networks contains a large number of almost degenerate minima \cite{Draxler2018EssentiallyLandscape}. In practice this means that if the model is trained long enough with a reasonable learning rate the details of the optimization are not having a major effect on the run-time performance. As a consequence the output of the trained network depends on the input, the model architecture and the training data. The different ingredients of a neural network model are illustrated on Figure~\ref{fig:data_attr}. When it comes to interpreting deep network models all of the parts on the diagram can serve as clues that can help in figuring out how the model might be ``thinking" and what the predictions are based on. \par

% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.85\textwidth]{Chapter3/Figs/Raster/data_attribution_diagram.png}
% \caption[Sear para IG]{Diagram showing the different ingredients affecting the predictions of machine learning models. }
% \label{fig:data_attr}
% \end{figure}

% That is why to interpret the predictions of neural network models one has to think about all three factors to gain as good an understanding as possible. In particular the training data as a crucial ingredient to the models and a tool for understanding models is often overlooked in the machine learning interpretability community. In this work we present a novel method for attributing neural network predictions to training data and re-purpose an existing tool, the Integrated Gradients, to Transformer models and use them in our protocol of interpretation. \par

% To go beyond interpretation meaning some nice and colourful diagrams that either look good and agree with human intuition or not, we give here a definition of interpretation and define an end-goal using which we can evaluate the explanations and verify or falsify them. By interpretability we mean the ability to reason associations and counterfactuals as well as the ability to query evidence in the data supporting a certain outcome. This means the a successful interpretation identifies factors that are related to a certain outcome and absence of factors related to absence of outcome. Furthermore this has to be supported by examples from the labelled training data. The validation of the interpretations happens in two ways. The first is by the design of adversarial examples that force the model into wrong predictions and the second is by identifying causes for the prediction in the training data. An example is if the wrong prediction is caused by erroneous data. \par

% %Thinking about the ingredients one by one, the model architecture defines a framework for the propagation of information. The understanding of the architecture can reveal what parts of the input may interact and how this information is turned into a prediction. This can sometimes be very helpful, for example in the case of image processing and convolutional neural networks the understanding of convolutional filters is essential for interpreting what features the model has learnt to recognize. Understanding the prediction in terms of the input can mean multiple things. The simplest approach is to determine how much different parts of the input are contributing to the prediction. This can give some clue about the basis of the predictions. For examples saliency maps can help visualize if a model is looking at the correct part of an image in the case of image recognition tasks \cite{Sturmfels2020VisualizingBaselines}. If for example it turns out that the sky in the background is important when labelling an image airplane than there is a good chance that the model has discovered a bias in the dataset. In this case the airplanes usually appeared in from of the sky, so model learnt to label airplane any image containing the sky rather than the airplane. The limitation of this approach is that attributing the model predictions to parts of the input tells us nothing about the interactions of the features the model has learnt. Finally attributing the predictions to training data can also be a very powerful tool both as an explanation for the predictions and also as a way of gaining some understanding of the inner workings of the model by looking at inputs the model finds similar. Another useful outcome can be the identification of erroneous data points. For example if the model predicts something incorrectly based on some training data points it can turn out that those points are mislabelled. In this case one can remove them from the training set or fix them and retrain the model. This way interpretability work can help directly improve the model. \par

% In the following, first the relevant literature of interpretable machine learning is briefly reviewed. It is followed by the description of our methods of interpreting chemical reaction prediction models and the Molecular Transformer \cite{Schwaller2019MolecularPrediction} in particular. This model builds on the Transformer architecture \cite{Vaswani2017} presented in detail in Chapter~\ref{chap:backgroun}. The two main pillars of our method are Integrated Gradients \cite{Sundararajan2017AxiomaticNetworks} for attributing the predictions to parts of the input. We adopt this method to the Molecular Transformer and reformulate it in the context of chemical reaction prediction. We also use this in a novel way to guide the construction of adversarial examples. Having identified the lack of methods for attributing neural network predictions to training data we present a new framework that allows for the quick and simple generation of attributions to data in different type of networks. We demonstrate it briefly for convolutional networks on the  MNIST dataset and in detail for the Molecular Transformer. 

% \section{Background on interpretable machine learning}
% Traditionally there have been two distinct approaches towards interpreting machine learning models. One can either use inherently interpretable models such as linear regression or turn to model agnostic interpretability methods. In the following a short summary is given of both approaches. 

% \subsection{Interpretable ML methods}

% There are three different interpretable machine learning methods in common use. Linear models are most often used for regression tasks when the goal is the prediction of a continuous target value. Usually the success of linear models depends on the basis function used. If the basis function are able to transform the inputs into a space where the fit is simple the model is going to perform well. For example in the case of fitting the potential energy of a molecule given the position of the atoms, the energy is a function that is invariant under the translation and the rotation of the atoms, so a good basis is one that transforms the Cartesian coordinates into a space that is invariant under these transformations \cite{Dusson2019ATOMICSTABILITY}. It is a general advantage of linear models, that it is easy to incorporate prior physical knowledge into them. The form of the linear model given an input vector $\bm{x}$ is:
% \begin{equation}
%     y(\bm{x}, \bm{w}) = w_0 + \sum^{M-1}_{j=1} w_j \phi_j(\bm{x})
% \end{equation}
% where $\phi_j$ are fixed basis functions and $w_j$ are weights learnt from training data. The interpretability comes from the fact that one can just read off how much each feature (basis function) contributes to the final prediction. This way at least the physics of the raw features can be clearly understood. This is especially helpful if the basis functions are constructed in a way that makes them interpretable i.e. they are physical descriptors of the system. \par
% The second highly interpretable models for classification (or sometimes regression) are decision trees. They work by learning a set of rules based on which the data can be split at each node until a leaf of the tree is reached which defines the output. A simple graphical illustration is shown on Figure~\ref{fig:decision_tree}.\par
% \begin{figure}
% \centering    
% \includegraphics[width=2.9in]{decision_tree.png}
% \caption{Graphical illustration of a decision tree}
% \label{fig:decision_tree}
% \end{figure}

% Finally the last class of interpretable machine learning models are the K-nearest neighbour classifiers. If one can define a kernel (similarity metric) between input points, than given a labelled training set it is possible to categorize any new input by taking the $K$ closest training points and outputting the prediction by a vote. The prediction will be the class that has the most members amongst the $K$ nearest neighbours of the input point. Here the training points provide the explanation to the prediction. These are the only models that provide exact interpretable attributions to training data.  

% \subsection{Model-agnostic interpretability methods}
% Model-agnostic interpretability methods aim to link the predictions directly to the inputs without having a reference to the specifics of the model. One way of explaining the predictions in a model agnostic way is to calculate the contribution of each input feature to the output. This has several limitation, for example this information does not say anything about the interactions of different features. It is useful nonetheless because just by knowing which features are important for a given prediction one can gain some insight into the workings of the model. In simple test cases where the relationship between input and output are well understood the attributions can serve as a way of sanity checking whether the model is making decisions for the right reason. 

% \subsubsection{Integrated Gradients}
% Integrated Gradients (IGs) is a model agnostic feature attribution method used in this work \cite{Sundararajan2017AxiomaticNetworks}. It can be used for any model where gradients are available. This is the case for all neural networks that are trained by some variant of gradient based optimization. \par
% Integrated Gradients are the adaptation of a method that long existed in the field of cooperative game theory \cite{Aumann1974ValuesGames}. The original problem was to calculate the contribution of each player to the gain when they are playing a cooperative game. This can be reformulated by identifying the players as the input features and the payout as the prediction of a neural network. This way the attribution will give the contribution of the different features as desired. To make the method work one needs to specify a non-informative baseline input. The ideal baseline is one that corresponds to a neutral prediction. For example in the case of image recognition tasks the usual baseline is the black image. The choice of baseline is a highly non-trivial problem and can have a major effect on the attributions \cite{Sturmfels2020VisualizingBaselines}. For the attribution of the output to truly reflect the contribution from each input feature it has to obey certain axioms of fairness:
% \begin{itemize}
%     \item Sensitivity: For every input and baseline that differ in one feature but have different predictions, the differing feature have to have non-zero attribution. 
%     \item Dummy: If the function implemented by the model does not depend on a feature than the attribution to it must always be zero.
%     \item Implementation invariance: If two models encode the same mathematical function, i.e. for identical inputs they have always the same output, than the attributions should also always agree. This is desirable because if an attribution method does not satisfy this property it might be sensitive to the specifics of the implementation.
%     \item Efficiency: The sum of the attributions on the features has to equal to the difference between the prediction and the prediction for the baseline. This means that all of the gain has to be attributed to the inputs. 
%     \item Symmetry: The attributions of symmetric features should be symmetric.  
% \end{itemize}
% \par
% To achieve this a number of path integrals methods were proposed in the game theory literature, IGs correspond to the Aumann-Shapley values \cite{Aumann1974ValuesGames}. \par
% Given a function $F:\mathbb{R}^n\to [0,1]$, the input $x\in\mathbb{R}^n$ and the baseline input $x'\in\mathbb{R}^n$ Integrated Gradients is the path integral along the straight line path from $x$ to $x'$ of the derivative of $F$ with respect to the input. So the Integrated Gradient attribution of feature $i$ is given by
% \begin{equation}
% \label{eqn:IG}
%     IG_i(x) = (x_i - x_i') \int_{\alpha=0}^1 \frac{\partial F(x' + \alpha(x-x'))}{\partial x_i} d\alpha
% \end{equation}
% By using this definition all of the above described desirable axioms are satisfied. Firstly the \emph{Efficiency} criteria holds as a simple consequence of the fundamental theorem of calculus for path integrals. From this the \emph{Sensitivity} criteria follows because the difference in the total attribution will be assigned to the only differing feature $i$. The \emph{Implementation invariance} is a simple consequence of using gradients. If two function are the same than their gradients are also the same. The \emph{Dummy} axiom is also trivially satisfied because the function is just a constant with respect to any variable it does not depend on. This results in the gradient to be zero everywhere. IGs are defined as the path integral from the baseline to the input of interest along a straight line path. The importance of the path being straight is that this is the unique path along which the attributions satisfy the \emph{Symmetry} property. The proof of this can be found in Ref~\cite{Sundararajan2017AxiomaticNetworks}. \par
% Due to the axiomatic nature and ease of implementation IGs had great success since their introduction to the deep learning community. They are increasingly used in the scientific community as well to gain some understanding of successful machine learning models. For example IGs have been used to decode binding mechanisms of small molecules to protein targets \cite{McCloskey2019UsingChemistry} or to highlight reaction related atoms in retrosynthesis models \cite{Ishida2019PredictionNetworks}. \par

% \section{Integrated Gradients for attributing reaction prediction}

% To interpret the predictions of the Molecular Transformer in terms of the input the first and highly non-trivial question to address is what a meaningful thing to attribute is. To ask what part of the reactant-reagent input is most important for predicting a given product is not an appropriate question. All of the input tokens contain crucial information that are used by the decoder to generate the entire target structure correctly. To eliminate this effect we decided to attribute the difference in predicted probability of two possible products. In this case since the inert parts of the input are the same for the two products they will not substantially contribute to their predicted probability difference. This method is especially suited for examining reactions with selectivities. For example in the case of electrophilic aromatic substitution reactions on substituted benzene rings the selectivity of the reactions are driven by the different directing groups. If the model is predicting the correct selectivity for the right reason the attributions on the directing groups should be large. This is demonstrated on Figure~\ref{fig:searpara} where the group expected to get large attribution is highlighted in red. These tests can help understand if the model has learnt true chemical principles which are crucial for good generalization. If it is found that the correct product is predicted for the wrong reason i.e. that attribution on the chemical group driving the selectivity is low, it can be confirmed that model has not been able to learn the underlying chemistry through the construction of adversarial examples. In these examples the parts of the input that the model finds important are unchanged and the parts that are chemically important but not according to the model are changed. This way the model can be fooled into incorrect predictions if the interpretation is correct, or if the model is able to predict the correct product for these examples the interpretation can be falsified. This is a crucial element of our method as any interpretation that cannot be falsified would be no more than speculation.  \par


% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.9\textwidth]{Chapter3/Figs/Raster/sear_para.png}
% \caption[Sear para]{Electrophilic aromatic substitution reaction with the directing group driving the selectivity circled in red.}
% \label{fig:searpara}
% \end{figure}

% The integrated gradients method provides a principled way of generating attributions that highlight parts of the input that are mostly responsible for the output \cite{Sundararajan2017AxiomaticNetworks}. In our implementation Integrated Gradients attribute the probability difference of two possible target molecules. This way integrated gradient attributions will give a score to each SMILES token of the input string that will be equal to their contribution to the probability difference between \texttt{target1} and \texttt{target2} compared to a non-informative baseline input:

% \begin{equation}
%     \sum_i IG_i = \Big(P(tgt_1 \mid src) - P(tgt_2 \mid src)\Big) - \Big(P(tgt_1 \mid baseline) - P(tgt_2 \mid baseline)\Big)
% \end{equation}

% where the sum is over the source tokens, $IG_i$ is the attribution of token $i$, $src$ is the reactant-reagent source string and $baseline$ is a non-informative input. \par

% To make this method work it is crucial to find a good non-informative baseline. This would traditionally be the black image in the case of image recognition as that doesn't contain any information. For reaction prediction from SMILES we decided to use the \texttt{'.'} token as the baseline, which is the character separating molecules. This is a reasonable choice because it does not encode any chemical information. \par

% In practice for a source of length $N$ each token has a 256 dimensional embedding. To have a baseline that is of the same dimension the embedding of the \texttt{'.'} token is taken $N$ times. This is advantageous compared to taking the embedding of $N$ dots as the input because this way the information stored in the positional encoding is also accounted for in the attributions. A linear path is generated in this $N \times 256$ dimensional space and for each of the inputs along that line the above probability difference is calculated and the gradients are summed up. Finally the attributions are summed for each token along the 256 dimensions. As a sanity check the sum of the attributions is compared to the actual probability difference and if they are not close enough the number of points along the linear path should be increased. Typically about 200 points are sufficient to converge to within 5\%, but in the next section all of the attributions were generated by discretizing the straight line path with 750 points. Even with this many points it only takes a couple of minutes to generate the attributions on a laptop. \par

% This protocol enables the calculation of attributions for the input SMILES strings but there  are some further issues to address before they start making sense. Reagents like sulphuric acid or meta-Chloroperoxybenzoic acid (mCPBA) are fed into the model by their full SMILES strings but they really are single units as far as the reaction is concerned. Their attributions are more meaningful to look at as a whole rather than token by token. A related problem is with the attributions corresponding to special characters in SMILES like numbers or parentheses. To this end we decided to specify some simple rules for summing the attributions for the SMILES characters into units that correspond to distinct substructures. Rings are considered as single units and their attribution is calculated by summing over the ring atoms and numbers corresponding to them. This way the information of the relative positions of the ring substituents will also be included in this part of the structure. Branches are also considered as single units and their attribution is the sum over their atoms and the parentheses specifying them. An example attribution for the reaction on figure~\ref{fig:searpara} is given in Table~\ref{table:searpara}.

% \begin{table}
% \caption{IG attributions of the reaction on Figure~\ref{fig:searpara}}
% \centering
% \label{table:searpara}
% \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
% \hline
% Br & Br & . & Br & [Fe] & ( & Br & ) & Br & . \\
% 0.024 & 0.010 & 0.002 & 0.019 & 0.060 & 0.034 & 0.052 & -0.023 & 0.029 & 0.054 \\ 
% \hline
% C & C & ( & C & ) & c & 1 & c & c & c \\
% -0.014 & -0.035 & 0.083 & 0.066 & 0.211 & 0.154 & 0.162 & 0.042 & 0.022 & -0.004\\
% \hline
% c & c & 1 & \multicolumn{7}{l|}{} \\
% -0.002 & -0.017 & 0.014 & \multicolumn{7}{l|}{} \\
% \hline
% \end{tabular}
% \end{table}

% From this, the actual interpretable attributions are created by summing the token attributions for the isopropyl group (including the parentheses), the benzene ring (including the numbers) and for the two reagents. The result with the final attributions giving the contribution to the probability difference of the two products is shown on Figure~\ref{fig:searparaIG}. The model predicts (correctly) the para product to be the major product. The attributions are showing that in this case the model is looking at the directing group and gives it a large attribution. When talking about the size of an attribution we always compare it to the amount of attribution the group would get if the probability difference would be distributed uniformly across the input tokens. This serves as a way of normalizing the attributions by the size of the different substructures. In this case uniform attribution would result in the isopropyl group getting 0.205 which is significantly less than the actual attribution which is 0.311. The rest of the probability difference is distributed roughly uniformly across the input source. 

% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.9\textwidth]{Chapter3/Figs/Raster/sear_para_IG.png}
% \caption[Sear para IG]{IG attribution of the relevant substructures.}
% \label{fig:searparaIG}
% \end{figure}

% \subsubsection{Implementation}
% The above described method was implemented in the Python programming language on top of the OpenNMT-py package \cite{Klein2017} which is built on Pytorch \cite{Paszke2019PyTorch:Library}. First the embedding tensor is calculated including the positional encoding. Then a number of input tensors are created by discretizing the linear path from the baseline to the source embedding with the number of points specified by the user. Then a functor object is built that takes a source embedding (including the positional encoding) as the input and calculates the probability difference of \texttt{target1} and \texttt{target2} given that embedding. It is followed by the calculation of the gradient of the probability difference for each embedding tensor along the linear path. Finally the IG attributions are calculated using Equation~\ref{eqn:IGapprox}. 
% \begin{equation}
%     IG_i(x) = (x_i - x_i') \times \sum_{k=1}^m \frac{\partial F(x' + \frac{k}{m} \times (x-x')}{\partial x_i} \times \frac{1}{m}
%     \label{eqn:IGapprox}
% \end{equation}
% where $IG_i$ is the attribution for dimension $i$ for the input $x$ and baseline input $x'$ and $m$ is the number of steps used to discretise the linear path from the baseline to the input source. Finally the attributions are summed along the 256 dimensions for each token and returned. The full code including a \texttt{README} with the usage can be found in the GitHub repo MTExplainer \cite{Kovacs2020MolecularExplainer}. 

% \section{Attributing the predictions of neural network models to training data}

% Attributing the predictions of neural networks to training data can serve as a tool for explaining predictions as well as gaining understanding of the models ``thinking". In cases when a model predicts something very unexpected to humans attributions to parts of the input can be difficult to make sense of. Sometimes it can be much more illustrative to see a couple of example inputs that the model finds similar. Usually seeing a number of similar examples can help humans identify the trend that serves as the basis of the prediction. This can either result in the discovery of new trends or laws in the scientific domain or it can reveal biases that the model has learnt. In this case this information can be used to improve the model or the dataset. Another possibility is that the model is predicting something unexpected based on items in the dataset that are erroneous. This can happen very often in the case of large noisy datasets like the ones that are used in the chemical reaction prediction field. The erroneous data points found this way can be deleted and the model can be retrained. \par
% To create a successful method for attribution to data the most crucial element is the careful design of a similarity measure. Ideally we would like to define similarity such that it measures how similar two input datapoints are according to the model. For different neural network architectures different choices of similarity measures can be appropriate. In the case of feed-forward or convolutional architectures a natural choice is to define a fingerprint vector for each data point that consists of the neural networks layer outputs (activations) concatenated together. These vectors can than be compared directly through a dot product or by using the Euclidean distance between them. We implemented this method for a simple convolutional neural network trained on the MNIST dataset. Here the task is the recognition of hand-written digits. An example from the test set is shown on Figure~\ref{fig:mnist}. This image is labelled as a 7 but for the human eye it could be a 1 as well.

% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=0.4\textwidth]{Chapter3/Figs/Raster/MNIST_pred.png}
% \caption[Sear para IG]{An example image from the MNIST dataset.}
% \label{fig:mnist}
% \end{figure}

% The model will assign a label to each image even if it is ambiguous for humans. The image on Figure~\ref{fig:mnist} is assigned correctly the number 7. To make this labelling more convincing a number of labelled training images that the model finds similar can be queried using the data attribution method. This way a more informed decision can be made whether or not the prediction of the model can be trusted. The top-12 most similar labelled training images are shown on Figure~\ref{fig:mnist_attr}. Looking at them it is quite obvious that the model is basing the prediction on a large number of similar labelled inputs, hence the prediction can probably be trusted.  \par

% \begin{figure}[htbp!] 
% \centering    
% \includegraphics[width=1.0\textwidth]{Chapter3/Figs/Raster/MNIST_attr.png}
% \caption[Sear para IG]{Top-12 most similar labelled training images according to data attribution to the example shown on Figure~\ref{fig:mnist}}
% \label{fig:mnist_attr}
% \end{figure}

% \subsection{Data attribution for the Molecular Transformer}

% In the case of the Molecular Transformer which has an encoder-decoder architecture the output of the encoder layers can be used as a basis for comparing data points. The challenge lies in the fact that these encoder hidden states do not have a fixed length. To overcome this we decided to use the 256 dimensional vector obtained by averaging the $N$ hidden state vectors. This choice makes sense as this way all information about the structure, reagents and reactivity are maintained and a fixed size representation is obtained. We hypothesized that averaging can work because of the relatively large dimensionality of the embedding space. The size of the vocabulary for the Molecular Transformer in the case of the USPTO dataset is 288 whereas for the Pistachio dataset it is 527. Representing 3-500 objects in a 256 dimensional space is very sparse and there is an opportunity to store different information in different parts of the 256 dimensional space. This way during the averaging step only minimal information will be lost. For each reaction in the training set the 256 dimensional hidden state vector is generated and saved as a binary. When a new example input is given it is passed through the Transformer encoder and the average hidden state vector of it is calculated. The similarity score of this vector to the training set vectors is calculated by
% \begin{equation}
%     score = \frac{1}{1 + D}
% \end{equation}
% where $D$ is the Euclidean distance between the vectors. This can be implemented in a vectorized way resulting in very quick computation even in the case of dataset sizes like Pistachio made up of over 2 million training examples. The top-n most similar reactions are returned where n is defined by the user. An implementation with a detailed \texttt{README} file is provided in the GitHub repo MTExplainer ~\cite{Kovacs2020MolecularExplainer}. 